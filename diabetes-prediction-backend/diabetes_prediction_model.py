# -*- coding: utf-8 -*-
"""diabetes-prediction-model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pf6eM2cmCAZiJrhMSCfrlPPTke2cgxco

# 1. Thu thập dữ liệu
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from scipy.stats.mstats import winsorize
from sklearn.feature_selection import SelectKBest, chi2, f_classif
from sklearn.model_selection import train_test_split

# Install dependencies as needed:
# pip install kagglehub[pandas-datasets]
import kagglehub
from kagglehub import KaggleDatasetAdapter

# Set the path to the file you'd like to load
file_path = "diabetes_binary_health_indicators_BRFSS2015.csv"

# Load the latest version
df = kagglehub.load_dataset(
  KaggleDatasetAdapter.PANDAS,
  "alexteboul/diabetes-health-indicators-dataset",
  file_path,
  # Provide any additional arguments like
  # sql_query or pandas_kwargs. See the
  # documenation for more information:
  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas
)

print("First 5 records:", df.head())

"""# 2. Mô tả chi tiết về tập dữ liệu"""

df.info()

"""# 3. Thống kê mô tả về tập dữ liệu

# 4. Làm sạch dữ liệu

## 4.1 Kiểm tra giá trị thiếu
"""

missing_values = df.isnull().sum()
missing_values

"""-> Không có giá trị thiếu

## 4.2 Kiểm tra giá trị độc nhất
"""

result = pd.DataFrame({
    "column": df.columns,
    "unique_values": [df[col].unique() for col in df.columns],
    "unique_count": [df[col].nunique() for col in df.columns]
})

result

"""## 4.3 Kiểm tra và loại bỏ giá trị trùng lặp"""

duplicates = df.duplicated().sum()
duplicates

"""-> Có 24206 dữ liệu trùng lặp"""

df = df.drop_duplicates()

df.info()

"""## 4.4 Xác định Outliers"""

features = ["BMI", "MentHlth", "PhysHlth", "Age", "Education", "Income", "GenHlth"]

plt.figure(figsize=(15, 10))

for i, col in enumerate(features, 1):
    plt.subplot(3, 3, i)
    sns.boxplot(y=df[col])
    plt.title(f"Boxplot of {col}")

plt.tight_layout()
plt.show()

"""- BMI

  - Có rất nhiều outliers, chủ yếu là BMI > 40.

  - BMI bình thường dao động ~18–35 → phần lớn giá trị >40 là bất thường (béo phì / có vấn đề liên quan đến cân nặng).

  - Outliers trải dài lên đến ~100, cho thấy dữ liệu bị lệch phải mạnh (right-skewed).

- MentHlth

  - Nhiều outliers > 5.

  - Đây là số ngày sức khỏe tâm lý kém trong 30 ngày → giá trị cao là hợp lệ.

  - Tuy nhiên phân bố lệch phải, phần lớn là 0–2 ngày, còn 20–30 ngày xuất hiện như outliers.

- PhysHlth

  - Tương tự MentHlth: phần lớn là 0–2, nhưng có nhiều giá trị 20–30.

  - Boxplot tạo ra nhiều điểm outlier do phân phối lệch.

- Age, Education, Income, GenHlth:
  - Tương đối ổn định, không có quá nhiều outliers đáng chú ý

# 5 Giải thích sự xuất hiện của các giá trị ngoại lai

## 5.1 Phân tích tổng quan dữ liệu của 3 biến BMI, MentHlth, PhysHlth
"""

df[["BMI", "MentHlth", "PhysHlth"]].describe()

"""- BMI:
  - Trung bình: 28,69 -> nằm trong phạm vi thừa cân quốc tế
  - Q3 = 32 nhưng Max = 98 vượt xa trung bình và các phân vị chính

  -> Có sự xuất hiện của các giá trị bất thường
- MentHlth:
  - Phân bố không đồng đều
  - Q3 = 2 ngày nghĩa là 75% dữ liệu người tham gia chỉ ghi nhận 2 ngày gặp vấn đề sức khỏe tinh thần trong tháng, tuy nhiên giá trị tối đa là 30 ngày:
  -> Có một số trường hợp đặc biệt ghi nhận vấn đề sức khỏe tinh thần cả tháng
- PhysHlth: tương tự như MentHlth

### 5.1.2 Xác định các giá trị hợp lý
"""

valid_ranges = {
    "BMI": (10, 60),
    "MentHlth": (0, 30),
    "PhysHlth": (0, 30)
}

for col, (low, high) in valid_ranges.items():
    invalid = df[(df[col] < low) | (df[col] > high)]
    valid = df[(df[col] >= low) & (df[col] <= high)]

    print(f"{col}:")
    print(f"  Giá trị KHÔNG hợp lý: {len(invalid)}")
    if len(invalid) > 0:
        print(invalid[[col]].head())
    print(f"  Giá trị hợp lý: {len(valid)}\n")

"""1. BMI

- Ngưỡng hợp lý: 10 - 60
- Tổng số giá trị hợp lý: 228669
- Tổng số giá trị không hợp lý: 805 chiếm 0.35%

2. MentHlth
- Ngưỡng hợp lý: 0 - 30
- Tổng số giá trị hợp lý: 229474
- Tổng số giá trị không hợp lý: 0

3. PhysHlth
- Ngưỡng hợp lý: 0 - 30
- Tổng số giá trị hợp lý: 229474
- Tổng số giá trị không hợp lý: 0

### 5.1.3 Xác định Outliers theo phương pháp IQR
"""

# Chọn các cột cần kiểm tra
columns = ["BMI", "MentHlth", "PhysHlth"]

for col in columns:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1

    # Xác định outliers
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]

    print(f"{col}:")
    print(f"  Q1 = {Q1}, Q3 = {Q3}, IQR = {IQR}")
    print(f"  Lower bound = {lower_bound}, Upper bound = {upper_bound}")
    print(f"  Số outliers: {len(outliers)}")
    if len(outliers) > 0:
        print(outliers[[col]].head())
    print()

"""1. BMI

- Ngưỡng dưới: 12
- Ngưỡng trên: 44
- Số lượng outliers: 5638 chiếm 2.46%

2. MentHlth

- Ngưỡng dưới: -3
- Ngưỡng trên: 5
- Số lượng outliers: 36162 chiếm 15.76%

3. PhysHlth

- Ngưỡng dưới: -6
- Ngưỡng trên: 10
- Số lượng outliers: 34346 chiếm 14.97%

## 5.2 Phân tích dữ liệu khám phá
"""

# Chỉ lấy các cột số để tính tương quan
numeric_cols = df.select_dtypes(include='number').columns
df_numeric = df[numeric_cols]

# Tính ma trận tương quan
corr_matrix = df_numeric.corr()

# Vẽ heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", cbar=True)
plt.title("Correlation Matrix of All Numeric Variables")
plt.show()

# Lấy ma trận tương quan tuyệt đối và loại bỏ đường chéo (tương quan 1 với chính nó)
corr_matrix_abs = corr_matrix.abs()
np.fill_diagonal(corr_matrix_abs.values, 0)

# Tìm giá trị tương quan cao nhất
max_corr = corr_matrix_abs.max().max()
max_pair = np.where(corr_matrix_abs == max_corr)
max_pair_cols = (numeric_cols[max_pair[0][0]], numeric_cols[max_pair[1][0]])

print(f"Cặp biến có tương quan cao nhất: {max_pair_cols} = {max_corr:.2f}")

"""-> Không có chỉ số tương quan nào >= 0.8 -> các feature không tác động lẫn nhau quá nhiều mà chỉ có ảnh hưởng lên biến phụ thuộc

Chia làm 2 nhóm:
- Mối quan hệ giữa từng biến độc lập chứa ngoại lai và GenHlth tới biến phụ thuộc Diabetes_binary
- Mối quan hệ giữa nhóm biến độc lập và biến phụ thuộc Diabetes_binary

# 6. Trực quan hóa dữ liệu

## 6.1 Mối quan hệ giữa từng biến độc lập chứa ngoại lai và GenHlth tới biến phụ thuộc Diabetes_binary
"""

# Tạo khoảng BMI (ví dụ mỗi bin 2 BMI)
bins = range(10, 61, 2)
labels = [f"{i}-{i+2}" for i in bins[:-1]]
df['BMI_bin'] = pd.cut(df['BMI'], bins=bins, labels=labels, right=False)

# Tính số lượng theo từng nhóm và từng bin
count_data = df.groupby(['BMI_bin', 'Diabetes_binary']).size().unstack(fill_value=0)

# Vẽ stacked bar chart
count_data.plot(kind='bar', stacked=True, color=['red', 'green'], figsize=(15,6))

plt.xlabel("BMI")
plt.ylabel("Số lượng")
plt.title("Relation between BMI and Diabetes Status")
plt.legend(["No Diabetic", "Diabetic"])
plt.xticks(rotation=45)
plt.show()

"""- Số lượng người không mắc tiểu đường chiếm ưu thế tuyệt đối ở hầu hết các nhóm BMI.
- Số người mắc tiểu đường rất ít ở nhóm BMI thấp, tăng dần khi BMI tăng và đạt đỉnh ở nhóm BMI cao, sau đó giảm mạnh ở BMI rất cao.
- Thừa cân và béo phì (BMI >= 25, đặc biệt 26–34) có liên quan rõ rệt với tăng nguy cơ tiểu đường.

-> Người có chỉ số BMI cao từ 25 trở lên có nguy cơ bị tiểu đường
"""

# Step 3: Data preparation
menthlth_counts = df.groupby(['MentHlth', 'Diabetes_binary']).size().unstack(fill_value=0)
menthlth_counts.columns = ['No Diabetes', 'Has Diabetes']
menthlth_counts = menthlth_counts.reset_index()

# Calculate percentage
menthlth_pct = menthlth_counts.copy()
total = menthlth_pct['No Diabetes'] + menthlth_pct['Has Diabetes']
menthlth_pct['Diabetes Prevalence (%)'] = (menthlth_pct['Has Diabetes'] / total * 100).round(2)

# Chart 1: Stacked bar chart - Frequency
fig1 = px.bar(menthlth_counts,
              x='MentHlth',
              y=['No Diabetes', 'Has Diabetes'],
              title='Frequency of Diabetes by Number of Poor Mental Health Days (MentHlth)',
              labels={'value': 'Number of People',
                      'MentHlth': 'Poor Mental Health Days (in past 30 days)'},
              color_discrete_sequence=['#1f77b4', '#d62728'],
              barmode='stack')

fig1.update_layout(
    height=600,
    xaxis=dict(tickmode='linear', dtick=1),
    legend_title="Diabetes Status",
    font=dict(size=12)
)
fig1.show()

# Chart 2: Line chart - Diabetes prevalence percentage
fig2 = px.line(menthlth_pct,
               x='MentHlth',
               y='Diabetes Prevalence (%)',
               title='Diabetes Prevalence (%) by Number of Poor Mental Health Days',
               markers=True)

fig2.add_scatter(x=menthlth_pct['MentHlth'],
                 y=menthlth_pct['Diabetes Prevalence (%)'],
                 mode='markers+lines',
                 marker=dict(color='red', size=8),
                 line=dict(color='red', width=3))

fig2.update_layout(
    height=600,
    xaxis=dict(title='Poor Mental Health Days (0–30)', tickmode='linear', dtick=2),
    yaxis=dict(title='Diabetes Prevalence (%)',
               range=[0, menthlth_pct['Diabetes Prevalence (%)'].max() + 5]),
    font=dict(size=12)
)

# Highlight the peak point
max_rate = menthlth_pct.loc[menthlth_pct['Diabetes Prevalence (%)'].idxmax()]
fig2.add_annotation(x=max_rate['MentHlth'],
                    y=max_rate['Diabetes Prevalence (%)'],
                    text=f"Peak: {max_rate['Diabetes Prevalence (%)']}% (day {int(max_rate['MentHlth'])})",
                    showarrow=True,
                    arrowhead=2,
                    ax=20,
                    ay=-30,
                    font=dict(color="red", size=12))

fig2.show()

"""- Người có ≥15 ngày sức khỏe tâm thần kém/tháng có nguy cơ mắc tiểu đường cao gấp đôi người khỏe mạnh về tâm lý.
- 0 ngày sức khỏe tinh thần kém: 15,2%
- 30 ngày sức khỏe tinh thần kém: 22,92%
- Nguy cơ cao nhất: 25% ở ngày 19
- Tỷ lệ phần trăm mắc bệnh tiểu đường có xu hướng tăng nhẹ khi sức khỏe tâm lý kém tăng

-> Không phải tất cả những người có sức khỏe tâm lý kém đều có khả nặng mắc bệnh tiểu đường nhưng họ có nguy cơ cao hơn
"""

# === PHYSICAL HEALTH (PhysHlth) vs Diabetes ===

# Step 1: Group and count
phys_counts = df.groupby(['PhysHlth', 'Diabetes_binary']).size().unstack(fill_value=0)
phys_counts.columns = ['No Diabetes', 'Has Diabetes']
phys_counts = phys_counts.reset_index()

# Step 2: Calculate percentage
phys_pct = phys_counts.copy()
total = phys_pct['No Diabetes'] + phys_pct['Has Diabetes']
phys_pct['Diabetes Prevalence (%)'] = (phys_pct['Has Diabetes'] / total * 100).round(2)

# Chart 1: Stacked bar – Frequency
fig1 = px.bar(phys_counts,
              x='PhysHlth',
              y=['No Diabetes', 'Has Diabetes'],
              title='Frequency of Diabetes by Number of Poor Physical Health Days (PhysHlth)',
              labels={'value': 'Number of People',
                      'PhysHlth': 'Poor Physical Health Days (in past 30 days)'},
              color_discrete_sequence=['#2ca02c', '#d62728'],
              barmode='stack')

fig1.update_layout(
    height=600,
    xaxis=dict(tickmode='linear', dtick=1),
    legend_title="Diabetes Status",
    font=dict(size=12)
)
fig1.show()

# Chart 2: Line chart – Diabetes prevalence percentage
fig2 = px.line(phys_pct,
               x='PhysHlth',
               y='Diabetes Prevalence (%)',
               title='Diabetes Prevalence (%) by Number of Poor Physical Health Days',
               markers=True,
               line_shape='linear')

fig2.add_scatter(x=phys_pct['PhysHlth'],
                 y=phys_pct['Diabetes Prevalence (%)'],
                 mode='markers+lines',
                 marker=dict(color='#d62728', size=9),
                 line=dict(color='#d62728', width=4))

fig2.update_layout(
    height=600,
    xaxis=dict(title='Poor Physical Health Days (0–30)', tickmode='linear', dtick=2),
    yaxis=dict(title='Diabetes Prevalence (%)',
               range=[0, phys_pct['Diabetes Prevalence (%)'].max() + 8]),
    font=dict(size=12)
)

# Highlight the peak
max_row = phys_pct.loc[phys_pct['Diabetes Prevalence (%)'].idxmax()]
peak_day = int(max_row['PhysHlth'])
peak_pct = max_row['Diabetes Prevalence (%)']

fig2.add_annotation(x=peak_day, y=peak_pct,
                    text=f"Peak: {peak_pct}% (day {peak_day})",
                    showarrow=True, arrowhead=2, ax=30, ay=-40,
                    font=dict(color="darkred", size=13, family="Arial Black"))

fig2.show()

"""- Có sự phân bố không đồng đều trong tần suất mắc bệnh
- 0 ngày sức khỏe thể chất kém -> tỷ lệ tiểu đường: 12,08%
- 30 ngày sức khỏe thể chất kém → Tỷ lệ tiểu đường: 29,53%
- Nguy cơ cao nhất: 34,42% vào ngày thứ 29
- Nguy cơ tăng gần như tuyến tính với số ngày sức khỏe thể chất kém

-> Sức khỏe thể chất là một yếu tố dự báo tiểu đường CỰC KỲ mạnh – thậm chí còn mạnh hơn cả Sức khỏe tinh thần (trong tập dữ liệu này)
"""

# GenHlth: 1=Excellent, 2=Very good, 3=Good, 4=Fair, 5=Poor
gen_counts = df['GenHlth'].groupby(df['Diabetes_binary']).value_counts().unstack(fill_value=0).T
gen_counts.columns = ['No Diabetes', 'Has Diabetes']
gen_counts = gen_counts.sort_index()
gen_counts = gen_counts.reset_index()

# Tính tỷ lệ phần trăm
gen_pct = gen_counts.copy()
total = gen_pct['No Diabetes'] + gen_pct['Has Diabetes']
gen_pct['Diabetes Prevalence (%)'] = (gen_pct['Has Diabetes'] / total * 100).round(2)

# Mapping để hiển thị chữ thay vì số
health_labels = {1: '1 - Excellent', 2: '2 - Very good', 3: '3 - Good', 4: '4 - Fair', 5: '5 - Poor'}
gen_counts['Health Status'] = gen_counts['GenHlth'].map(health_labels)
gen_pct['Health Status'] = gen_pct['GenHlth'].map(health_labels)

# Biểu đồ 1: Stacked bar - Số lượng người
fig1 = px.bar(gen_counts,
              x='Health Status',
              y=['No Diabetes', 'Has Diabetes'],
              title='Frequency of Diabetes by Self-Rated General Health (GenHlth)',
              labels={'value': 'Number of People', 'Health Status': 'Self-Rated General Health'},
              color_discrete_sequence=['#1f77b4', '#d62728'],
              barmode='stack')

fig1.update_layout(height=600, legend_title="Diabetes Status")
fig1.show()

# Biểu đồ 2: Biểu đồ tần suất riêng biệt (2 cột song song) - rất dễ so sánh
fig2 = px.bar(gen_counts,
              x='Health Status',
              y=['No Diabetes', 'Has Diabetes'],
              title='Diabetes Frequency Distribution by Self-Rated General Health',
              labels={'value': 'Number of People',
                      'Health Status': 'Self-Rated General Health (1=Excellent → 5=Poor)'},
              color_discrete_sequence=['#1f77b4', '#d62728'],
              barmode='group') # ← Đã xóa 'side_by_side=True'

fig2.update_layout(
    height=620,
    legend_title="Diabetes Status",
    xaxis_title="Self-Rated General Health<br><sub>1 = Excellent, 2 = Very good, 3 = Good, 4 = Fair, 5 = Poor</sub>",
    yaxis_title="Number of People",
    bargap=0.3,
    font=dict(size=13)
)

# Thêm số liệu trên đầu cột cho dễ đọc
fig2.update_traces(texttemplate='%{y:,}', textposition='outside')

fig2.show()

"""- Càng tự đánh giá sức khỏe tổng quát kém → càng nhiều người mắc đái tháo đường.
- Tỷ lệ và số lượng tuyệt đối đều tăng dần đều.

-> Có mối quan hệ mạnh mẽ giữa sức khỏe tổng quảt và nguy cơ mắc bệnh tiểu đường

## 6.2 Mối quan hệ giữa nhóm biến độc lập và biến phụ thuộc Diabetes_binary
"""

# Hàm tính thống kê
def calc_stats(group_var):
    stats = df.groupby(group_var)['Diabetes_binary'].agg(
        mean='mean', count='count', std='std'
    ).reset_index()
    stats['sem'] = stats['std'] / np.sqrt(stats['count'])
    return stats

highbp_stats = calc_stats('HighBP')
highchol_stats = calc_stats('HighChol')

# Chuẩn bị dữ liệu cho biểu đồ
def prepare_data(stats, label_map):
    # stats có index 0 -> group 0, index 1 -> group 1
    data = pd.DataFrame({
        'Group_Label': [label_map[0], label_map[0], label_map[1], label_map[1]],
        'Diabetes_Status': ['No Diabetes', 'Diabetes', 'No Diabetes', 'Diabetes'],
        'Proportion': [
            1 - stats.loc[0, 'mean'], stats.loc[0, 'mean'],
            1 - stats.loc[1, 'mean'], stats.loc[1, 'mean']
        ],
        'Error': [
            stats.loc[0, 'sem'], stats.loc[0, 'sem'],
            stats.loc[1, 'sem'], stats.loc[1, 'sem']
        ]
    })
    return data

data_bp = prepare_data(highbp_stats, {0: 'No High BP', 1: 'High BP'})
data_chol = prepare_data(highchol_stats, {0: 'Normal Cholesterol', 1: 'High Cholesterol'})

# Tạo biểu đồ song song
fig = make_subplots(rows=1, cols=2, subplot_titles=("", ""), horizontal_spacing=0.12)

# Biểu đồ HighBP
for status, color in zip(['No Diabetes', 'Diabetes'], ['#4C78A8', '#F58518']):
    subset = data_bp[data_bp['Diabetes_Status'] == status]
    fig.add_trace(go.Bar(
        x=subset['Group_Label'],
        y=subset['Proportion'],
        name=status,
        marker_color=color,
        error_y=dict(type='data', array=subset['Error'], color='black', thickness=2.5, width=10),
        text=subset['Proportion'].round(3),
        textposition='outside'
    ), row=1, col=1)

# Biểu đồ HighChol
for status, color in zip(['No Diabetes', 'Diabetes'], ['#4C78A8', '#F58518']):
    subset = data_chol[data_chol['Diabetes_Status'] == status]
    fig.add_trace(go.Bar(
        x=subset['Group_Label'],
        y=subset['Proportion'],
        name=status,
        marker_color=color,
        error_y=dict(type='data', array=subset['Error'], color='black', thickness=2.5, width=10),
        text=subset['Proportion'].round(3),
        textposition='outside',
        showlegend=False  # Ẩn legend thứ 2 để không bị lặp
    ), row=1, col=2)

# Cập nhật layout
fig.update_layout(
    height=600,
    width=1100,
    title_text="<b>Diabetes Prevalence by BP and Cholesterol Status</b>",
    title_x=0.5,
    title_font_size=22,
    font=dict(family="Arial", size=14),
    plot_bgcolor='white',
    paper_bgcolor='white',
    barmode='group',
    bargap=0.5,
    legend=dict(
        title="Diabetes Status",
        orientation="h",
        yanchor="bottom", y=1.02,
        xanchor="right", x=1,
        bgcolor="rgba(255,255,255,0.9)",
        bordercolor="gray",
        borderwidth=1
    )
)

fig.update_yaxes(title_text="Proportion of Individuals", range=[0, 0.8], tickformat='.2f', gridcolor='lightgray')
fig.update_xaxes(title_text="<b>High Blood Pressure Status</b>", row=1, col=1)
fig.update_xaxes(title_text="<b>High Cholesterol Status</b>", row=1, col=2)

fig.show()

"""- Ở nhóm Huyết áp Cao (High BP): tỷ lệ cá nhân mắc bệnh tiểu đường là 25.3%. Ở nhóm Huyết áp Không Cao (No High BP), tỷ lệ mắc tiểu đường chỉ là 6.9%

  -> Những người có huyết áp cao có nguy cơ mắc bệnh tiểu đường cao hơn đáng kể so với những người có huyết áp bình thường.
- Ở nhóm Cholesterol Cao (High Cholesterol), tỷ lệ cá nhân mắc bệnh tiểu đường là 23.2%.Ở nhóm Cholesterol Bình thường (Normal Cholesterol), tỷ lệ mắc tiểu đường chỉ là 9.1%.

  ->  Tương tự như huyết áp, những người có mức cholesterol cao có nguy cơ mắc bệnh tiểu đường cao hơn.

=> HighBP và HighChol đểu làm tăng nguy cơ xuất hiện bệnh tiểu đường, đặc biệt là khi cả 2 yếu tố này cùng xuất hiện
"""

grouped_stats = df.groupby(['Smoker', 'HvyAlcoholConsump'])['Diabetes_binary'].agg(
    mean_diabetes='mean',
    count_individuals='count',
    std_diabetes='std'
).reset_index()

# Calculate Standard Error of the Mean (SEM)
grouped_stats['sem_diabetes'] = grouped_stats['std_diabetes'] / np.sqrt(grouped_stats['count_individuals'])


fig = px.bar(
    grouped_stats,
    x='Smoker',
    y='mean_diabetes',
    color='HvyAlcoholConsump',
    error_y='sem_diabetes',
    barmode='group',
    title='Diabetes Prevalence by Smoking and Heavy Alcohol Consumption Status',
    labels={
        'Smoker': 'Smoker Status (0: No, 1: Yes)',
        'HvyAlcoholConsump': 'Heavy Alcohol Consumption (0: No, 1: Yes)',
        'mean_diabetes': 'Diabetes Prevalence (Mean)'
    },
    height=600,
    color_discrete_map={0: '#636EFA', 1: '#EF553B'}
)

fig.update_layout(
    xaxis = dict(
        tickmode = 'array',
        tickvals = [0, 1],
        ticktext = ['Non-Smoker', 'Smoker']
    ),
    legend_title='Heavy Alcohol Consump.',
    font=dict(size=12)
)
fig.show()

"""- Trong số những người không hút thuốc, những người không uống rượu nhiều có tỷ lệ mắc bệnh tiểu đường khoảng 14,15% (SEM ~ 0,001016), trong khi những người uống rượu nhiều có tỷ lệ mắc bệnh thấp hơn đáng kể, khoảng 4,41% (SEM ~ 0,002958).
- Tương tự, trong số những người hút thuốc, những người không uống rượu nhiều có tỷ lệ mắc bệnh tiểu đường khoảng 18,01% (SEM ~ 0,001229), trong khi những người uống rượu nhiều có tỷ lệ mắc bệnh thấp hơn, khoảng 6,78% (SEM ~ 0,002633).

-> Thói quen hút thuốc và uống rượu có sự liên hệ nhất định đến bệnh tiểu đường, tuy nhiên mối tương quan chưa mạnh.
"""

stroke_heart_stats = df.groupby(['Stroke', 'HeartDiseaseorAttack'])['Diabetes_binary'].agg(
    mean_diabetes='mean',
    count_individuals='count',
    std_diabetes='std'
).reset_index()

# Calculate Standard Error of the Mean (SEM)
stroke_heart_stats['sem_diabetes'] = stroke_heart_stats['std_diabetes'] / np.sqrt(stroke_heart_stats['count_individuals'])

fig = px.bar(
    stroke_heart_stats,
    x='Stroke',
    y='mean_diabetes',
    color='HeartDiseaseorAttack',
    error_y='sem_diabetes',
    barmode='group',
    title='Diabetes Prevalence by Stroke and Heart Disease Status',
    labels={
        'Stroke': 'Stroke (0: No, 1: Yes)',
        'HeartDiseaseorAttack': 'Heart Disease (0: No, 1: Yes)',
        'mean_diabetes': 'Diabetes Prevalence (Mean)'
    },
    height=600,
    color_discrete_map={0: '#636EFA', 1: '#EF553B'}
)

fig.update_layout(
    xaxis = dict(
        tickmode = 'array',
        tickvals = [0, 1],
        ticktext = ['No Stroke', 'Stroke']
    ),
    legend_title='Heart Disease or Attack',
    font=dict(size=12)
)
fig.show()

"""- Những người không bị đột quỵ và không mắc bệnh tim có tỷ lệ mắc bệnh khoảng 0,1284.
- Những người không bị đột quỵ nhưng mắc bệnh tim có tỷ lệ mắc bệnh khoảng 0,2872.
- Những người bị đột quỵ nhưng không mắc bệnh tim có tỷ lệ mắc bệnh khoảng 0,2312.
- Những người vừa bị đột quỵ vừa mắc bệnh tim có tỷ lệ mắc bệnh cao nhất, khoảng 0,4157.

-> Đột quỵ và bệnh tim (cơn đau tim) đều làm tăng đáng kể nguy cơ mắc bệnh tiểu đường, đặc biệt khi cả 2 yếu tố này cùng đồng thời xuất hiện.
"""

physactivity_stats = calc_stats('PhysActivity')
fruits_stats = calc_stats('Fruits')
veggies_stats = calc_stats('Veggies')

physactivity_label_map = {0: 'No Physical Activity', 1: 'Physical Activity'}
fruits_label_map = {0: 'No Fruit Consumption', 1: 'Fruit Consumption'}
veggies_label_map = {0: 'No Veggie Consumption', 1: 'Veggie Consumption'}

data_physactivity = prepare_data(physactivity_stats, physactivity_label_map)
data_fruits = prepare_data(fruits_stats, fruits_label_map)
data_veggies = prepare_data(veggies_stats, veggies_label_map)

fig = make_subplots(rows=1, cols=3,
                    subplot_titles=("<b>Diabetes Prevalence by Physical Activity</b>",
                                    "<b>Diabetes Prevalence by Fruit Consumption</b>",
                                    "<b>Diabetes Prevalence by Vegetable Consumption</b>"),
                    horizontal_spacing=0.08)

df['BMI_bin'] = pd.cut(df['BMI'], bins=range(10, 61, 2), labels=[f"{i}-{i+2}" for i in range(10, 61, 2)[:-1]], right=False)

# Define consistent colors for Diabetes Status
diabetes_colors = {'No Diabetes': '#4C78A8', 'Diabetes': '#F58518'}

# Add traces for PhysActivity
for status, color in diabetes_colors.items():
    subset = data_physactivity[data_physactivity['Diabetes_Status'] == status]
    fig.add_trace(go.Bar(
        x=subset['Group_Label'],
        y=subset['Proportion'],
        name=status,
        marker_color=color,
        error_y=dict(type='data', array=subset['Error'], color='black', thickness=2.5, width=10),
        text=subset['Proportion'].round(3),
        textposition='outside',
        showlegend=True if status == 'No Diabetes' else False # Show legend only once for 'No Diabetes'
    ), row=1, col=1)

# Add traces for Fruits
for status, color in diabetes_colors.items():
    subset = data_fruits[data_fruits['Diabetes_Status'] == status]
    fig.add_trace(go.Bar(
        x=subset['Group_Label'],
        y=subset['Proportion'],
        name=status,
        marker_color=color,
        error_y=dict(type='data', array=subset['Error'], color='black', thickness=2.5, width=10),
        text=subset['Proportion'].round(3),
        textposition='outside',
        showlegend=False # Do not show legend for subsequent groups to avoid repetition
    ), row=1, col=2)

# Add traces for Veggies
for status, color in diabetes_colors.items():
    subset = data_veggies[data_veggies['Diabetes_Status'] == status]
    fig.add_trace(go.Bar(
        x=subset['Group_Label'],
        y=subset['Proportion'],
        name=status,
        marker_color=color,
        error_y=dict(type='data', array=subset['Error'], color='black', thickness=2.5, width=10),
        text=subset['Proportion'].round(3),
        textposition='outside',
        showlegend=False # Do not show legend for subsequent groups to avoid repetition
    ), row=1, col=3)

# Update layout
fig.update_layout(
    height=600,
    width=1300,
    title_text="<b>Diabetes Prevalence by Lifestyle Factors</b>",
    title_x=0.5,
    title_font_size=24,
    font=dict(family="Arial", size=12),
    plot_bgcolor='white',
    paper_bgcolor='white',
    barmode='group',
    bargap=0.3,
    legend=dict(
        title="Diabetes Status",
        orientation="h",
        yanchor="bottom", y=1.05,
        xanchor="center", x=0.5,
        bgcolor="rgba(255,255,255,0.9)",
        bordercolor="gray",
        borderwidth=1
    )
)

# Update y-axes properties
fig.update_yaxes(title_text="Proportion of Individuals", range=[0, 0.4], tickformat='.2f', gridcolor='lightgray')
fig.update_xaxes(title_text="<b>Physical Activity</b>", row=1, col=1, title_font=dict(size=14))
fig.update_xaxes(title_text="<b>Fruit Consumption</b>", row=1, col=2, title_font=dict(size=14))
fig.update_xaxes(title_text="<b>Vegetable Consumption</b>", row=1, col=3, title_font=dict(size=14))

fig.show()

"""- Những người không hoạt động thể chất có tỷ lệ mắc bệnh tiểu đường cao hơn (khoảng 21,3%) so với những người hoạt động thể chất (khoảng 13,1%).
- Việc tiêu thụ trái cây có liên quan đến tỷ lệ mắc bệnh tiểu đường thấp hơn: 14,6% đối với những người ăn trái cây so với 16,4% đối với những người không ăn trái cây.
- Tương tự, việc tiêu thụ rau có tương quan với tỷ lệ mắc bệnh tiểu đường thấp hơn: 14,5% đối với những người ăn rau so với 18,2% đối với những người không ăn.

-> Việc duy trì hoạt động thể chất và tiêu thụ đủ trái cây và rau củ có thể là những yếu tố quan trọng trong việc giảm nguy cơ mắc bệnh tiểu đường.
"""

no_doc_healthcare_stats = df.groupby(['NoDocbcCost', 'AnyHealthcare'])['Diabetes_binary'].agg(
    mean_diabetes='mean',
    count_individuals='count',
    std_diabetes='std'
).reset_index()

# Calculate Standard Error of the Mean (SEM)
no_doc_healthcare_stats['sem_diabetes'] = no_doc_healthcare_stats['std_diabetes'] / np.sqrt(no_doc_healthcare_stats['count_individuals'])

def prepare_data_extended(stats_df):
    # Create descriptive labels for NoDocbcCost and AnyHealthcare
    no_doc_cost_map = {0.0: 'No Cost', 1.0: 'Had Cost'}
    any_healthcare_map = {0.0: 'No Healthcare', 1.0: 'Had Healthcare'}

    # Apply mappings to create new columns with descriptive labels
    stats_df['NoDocbcCost_Label'] = stats_df['NoDocbcCost'].map(no_doc_cost_map)
    stats_df['AnyHealthcare_Label'] = stats_df['AnyHealthcare'].map(any_healthcare_map)

    # Create a combined label for the x-axis
    stats_df['Combined_Label'] = stats_df.apply(lambda row: f"{row['NoDocbcCost_Label']} & {row['AnyHealthcare_Label']}", axis=1)

    # Initialize an empty list to store prepared data
    prepared_data = []

    # Iterate through each row of the stats_df to create 'No Diabetes' and 'Has Diabetes' entries
    for index, row in stats_df.iterrows():
        # Entry for 'Has Diabetes'
        prepared_data.append({
            'Combined_Label': row['Combined_Label'],
            'Diabetes_Status': 'Has Diabetes',
            'Proportion': row['mean_diabetes'],
            'Error': row['sem_diabetes']
        })
        # Entry for 'No Diabetes'
        prepared_data.append({
            'Combined_Label': row['Combined_Label'],
            'Diabetes_Status': 'No Diabetes',
            'Proportion': 1 - row['mean_diabetes'],
            'Error': row['sem_diabetes'] # SEM applies to the mean, so it's the same for 1-mean
        })

    # Convert the list of dictionaries to a DataFrame
    return pd.DataFrame(prepared_data)

# Apply the function to no_doc_healthcare_stats
data_no_doc_healthcare = prepare_data_extended(no_doc_healthcare_stats)

import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Create a figure with a single subplot
fig = make_subplots(rows=1, cols=1)

# Define consistent colors for Diabetes Status
diabetes_colors = {'No Diabetes': '#4C78A8', 'Has Diabetes': '#F58518'}

# Add traces for each diabetes status
for status, color in diabetes_colors.items():
    subset = data_no_doc_healthcare[data_no_doc_healthcare['Diabetes_Status'] == status]
    fig.add_trace(go.Bar(
        x=subset['Combined_Label'],
        y=subset['Proportion'],
        name=status,
        marker_color=color,
        error_y=dict(type='data', array=subset['Error'], color='black', thickness=2.5, width=10),
        text=subset['Proportion'].round(3),
        textposition='outside'
    ), row=1, col=1)

# Update layout
fig.update_layout(
    height=600,
    width=1000,
    title_text="<b>Diabetes Prevalence by Healthcare Access & Cost Perception</b>",
    title_x=0.5,
    title_font_size=22,
    font=dict(family="Arial", size=14),
    plot_bgcolor='white',
    paper_bgcolor='white',
    barmode='group',
    bargap=0.3,
    legend=dict(
        title="Diabetes Status",
        orientation="h",
        yanchor="bottom", y=1.02,
        xanchor="center", x=0.5,
        bgcolor="rgba(255,255,255,0.9)",
        bordercolor="gray",
        borderwidth=1
    )
)

fig.update_yaxes(title_text="Proportion of Individuals", range=[0, 1.0], tickformat='.2f', gridcolor='lightgray')
fig.update_xaxes(
    title_text="<b>Access to Healthcare & Cost Barrier</b>",
    tickangle=15, # Rotate x-axis labels for better readability
    categoryorder='array',
    categoryarray=data_no_doc_healthcare['Combined_Label'].unique()
)

fig.show()

"""- Tỷ lệ mắc bệnh tiểu đường thấp nhất (khoảng 10,3%) được ghi nhận ở những người báo cáo không gặp rào cản về chi phí khi đi khám bác sĩ và không được tiếp cận bất kỳ dịch vụ bảo hiểm chăm sóc sức khỏe nào.
- Tỷ lệ mắc bệnh tiểu đường cao nhất (khoảng 18,6%) được ghi nhận ở những người báo cáo gặp rào cản về chi phí khi đi khám bác sĩ nhưng có một số hình thức  bảo hiểm chăm sóc sức khỏe.

-> Việc duy trì hoạt động sử dụng dịch vụ bảo hiểm chăm sóc sức khỏe và không gặp rào cản về chi phí là những yếu tố quan trọng trong giúp giảm nguy cơ tiểu đường.
"""

def calc_stats(group_var):
    stats = df.groupby(group_var)['Diabetes_binary'].agg(
        mean='mean', count='count', std='std'
    ).reset_index()
    stats['sem'] = stats['std'] / np.sqrt(stats['count'])
    return stats

def prepare_data(stats, label_map):
    data = pd.DataFrame({
        'Group_Label': [label_map[item] for item in stats[stats.columns[0]] for _ in (0,1)],
        'Diabetes_Status': ['No Diabetes', 'Diabetes'] * len(stats),
        'Proportion': np.concatenate([[1 - row['mean'], row['mean']] for _, row in stats.iterrows()]),
        'Error': np.concatenate([[row['sem'], row['sem']] for _, row in stats.iterrows()])
    })
    return data

# Define label maps if not already defined
sex_label_map = {0.0: 'Female', 1.0: 'Male'}
age_label_map = {1.0: '18-24', 2.0: '25-29', 3.0: '30-34', 4.0: '35-39', 5.0: '40-44', 6.0: '45-49', 7.0: '50-54', 8.0: '55-59', 9.0: '60-64', 10.0: '65-69', 11.0: '70-74', 12.0: '75-79', 13.0: '80+'}
education_label_map = {1.0: 'No High School', 2.0: 'High School Grad', 3.0: 'Some College', 4.0: 'College Grad', 5.0: 'Associate Degree', 6.0: 'Bachelors/Masters'}
income_label_map = {1.0: '<$10k', 2.0: '$10k-$15k', 3.0: '$15k-$20k', 4.0: '$20k-$25k', 5.0: '$25k-$35k', 6.0: '$35k-$50k', 7.0: '$50k-$75k', 8.0: '>$75k'}

# Calculate statistics
sex_stats = calc_stats('Sex')
age_stats = calc_stats('Age')
education_stats = calc_stats('Education')
income_stats = calc_stats('Income')

# Prepare data for plotting
data_sex = prepare_data(sex_stats, sex_label_map)
data_age = prepare_data(age_stats, age_label_map)
data_education = prepare_data(education_stats, education_label_map)
data_income = prepare_data(income_stats, income_label_map)

fig = make_subplots(rows=2, cols=2,
                    subplot_titles=("<b>Diabetes Prevalence by Sex</b>",
                                    "<b>Diabetes Prevalence by Age Group</b>",
                                    "<b>Diabetes Prevalence by Education Level</b>",
                                    "<b>Diabetes Prevalence by Income Level</b>"))

data_sets = {
    'Sex': data_sex,
    'Age': data_age,
    'Education': data_education,
    'Income': data_income
}

rows_cols = [(1, 1), (1, 2), (2, 1), (2, 2)]

# Define consistent colors for Diabetes Status
diabetes_colors = {'No Diabetes': '#4C78A8', 'Diabetes': '#F58518'}

for i, (title_key, df_data) in enumerate(data_sets.items()):
    row, col = rows_cols[i]
    for status, color in diabetes_colors.items():
        subset = df_data[df_data['Diabetes_Status'] == status]
        fig.add_trace(go.Bar(
            x=subset['Group_Label'],
            y=subset['Proportion'],
            name=status,
            marker_color=color,
            error_y=dict(type='data', array=subset['Error'], color='black', thickness=2.5, width=10),
            text=subset['Proportion'].round(3),
            textposition='outside',
            showlegend=True if (row == 1 and col == 1 and status == 'No Diabetes') else False # Show legend only once
        ), row=row, col=col)

# Update layout
fig.update_layout(
    height=1000,
    width=1400,
    title_text="<b>Diabetes Prevalence by Demographic Factors</b>",
    title_x=0.5,
    title_font_size=24,
    font=dict(family="Arial", size=12),
    plot_bgcolor='white',
    paper_bgcolor='white',
    barmode='group',
    bargap=0.3,
    legend=dict(
        title="Diabetes Status",
        orientation="h",
        yanchor="bottom", y=1.03,
        xanchor="center", x=0.5,
        bgcolor="rgba(255,255,255,0.9)",
        bordercolor="gray",
        borderwidth=1
    )
)

# Update y-axes properties for all subplots
fig.update_yaxes(title_text="Proportion of Individuals", range=[0, 1.0], tickformat='.2f', gridcolor='lightgray')

# Specific x-axis title adjustments
fig.update_xaxes(title_text="<b>Sex</b>", row=1, col=1, title_font=dict(size=14))
fig.update_xaxes(title_text="<b>Age Group</b>", row=1, col=2, title_font=dict(size=14))
fig.update_xaxes(title_text="<b>Education Level</b>", row=2, col=1, title_font=dict(size=14), tickangle=20)
fig.update_xaxes(title_text="<b>Income Level</b>", row=2, col=2, title_font=dict(size=14), tickangle=20)

fig.show()

"""- Theo giới tính (Sex):
  - Không có sự khác biệt lắm, cả nam và nữ đều có tỷ lệ mắc bệnh tương tự.

- Theo nhóm tuổi (Age Group):
  - Tỷ lệ mắc tiểu đường tăng rất rõ theo tuổi tác.
  - Nhóm tuổi trẻ (18–44 tuổi): rất thấp (chỉ 2–5%).
  - Từ 45 tuổi trở lên bắt đầu tăng mạnh, đạt đỉnh ở nhóm 55–59 tuổi (khoảng 22%).
  - Sau 60 tuổi vẫn duy trì ở mức cao (18–22%), nhóm 80+ giảm nhẹ xuống còn ~18%.

→ Tuổi tác là yếu tố nguy cơ mạnh nhất của bệnh tiểu đường loại 2.

- Theo trình độ học vấn (Education Level):
  - Người có trình độ học vấn càng thấp thì tỷ lệ mắc tiểu đường càng cao.
  - Không tốt nghiệp phổ thông: ~27%
  - Tốt nghiệp phổ thông: ~24,3%
  - Một phần đại học: ~24,3%
  - Tốt nghiệp đại học trở lên: chỉ còn 11,6–15,5%

→ Người ít học có nguy cơ mắc tiểu đường cao gấp đôi so với người có bằng đại học/cử nhân.

- Theo mức thu nhập (Income Level):
  - Thu nhập càng thấp thì tỷ lệ mắc tiểu đường càng cao.
  - Nhóm thu nhập <10k/năm: 24,3%
  - Nhóm 10–25k: ~22–23%
  - Nhóm thu nhập cao nhất (>75k/năm): chỉ còn 8,8%

→ Có mối liên hệ ngược rất rõ ràng giữa thu nhập và tỷ lệ mắc tiểu đường: nghèo → nguy cơ cao gấp gần 3 lần so với người giàu.

- Bệnh tiểu đường phổ biến nhất ở những người: lớn tuổi, nam giới, trình độ học vấn thấp, và đặc biệt là thu nhập thấp.
- Yếu tố kinh tế - xã hội (thu nhập và học vấn) có ảnh hưởng cực kỳ mạnh đến tỷ lệ mắc bệnh tiểu đường, thậm chí còn rõ rệt hơn cả yếu tố giới tính.
- Tuổi tác vẫn là yếu tố nguy cơ quan trọng nhất, nhưng trong cùng độ tuổi, người nghèo và ít học vẫn có nguy cơ cao hơn rất nhiều.
"""

diffwalk_stats = calc_stats('DiffWalk')
cholcheck_stats = calc_stats('CholCheck')

diffwalk_label_map = {0: 'No DiffWalk', 1: 'Has DiffWalk'}
cholcheck_label_map = {0: 'No CholCheck', 1: 'Has CholCheck'}

data_diffwalk = prepare_data(diffwalk_stats, diffwalk_label_map)
data_cholcheck = prepare_data(cholcheck_stats, cholcheck_label_map)

fig = make_subplots(rows=1, cols=2,
                    subplot_titles=("<b>Diabetes Prevalence by DiffWalk Status</b>",
                                    "<b>Diabetes Prevalence by CholCheck Status</b>"),
                    horizontal_spacing=0.12)

# Define consistent colors for Diabetes Status
diabetes_colors = {'No Diabetes': '#4C78A8', 'Diabetes': '#F58518'}

# Add traces for DiffWalk
for status, color in diabetes_colors.items():
    subset = data_diffwalk[data_diffwalk['Diabetes_Status'] == status]
    fig.add_trace(go.Bar(
        x=subset['Group_Label'],
        y=subset['Proportion'],
        name=status,
        marker_color=color,
        error_y=dict(type='data', array=subset['Error'], color='black', thickness=2.5, width=10),
        text=subset['Proportion'].round(3),
        textposition='outside',
        showlegend=True if status == 'No Diabetes' else False # Show legend only once for 'No Diabetes'
    ), row=1, col=1)

# Add traces for CholCheck
for status, color in diabetes_colors.items():
    subset = data_cholcheck[data_cholcheck['Diabetes_Status'] == status]
    fig.add_trace(go.Bar(
        x=subset['Group_Label'],
        y=subset['Proportion'],
        name=status,
        marker_color=color,
        error_y=dict(type='data', array=subset['Error'], color='black', thickness=2.5, width=10),
        text=subset['Proportion'].round(3),
        textposition='outside',
        showlegend=False # Do not show legend for subsequent groups to avoid repetition
    ), row=1, col=2)

# Update layout
fig.update_layout(
    height=600,
    width=1100,
    title_text="<b>Diabetes Prevalence by DiffWalk and CholCheck Status</b>",
    title_x=0.5,
    title_font_size=22,
    font=dict(family="Arial", size=14),
    plot_bgcolor='white',
    paper_bgcolor='white',
    barmode='group',
    bargap=0.3,
    legend=dict(
        title="Diabetes Status",
        orientation="h",
        yanchor="bottom", y=1.02,
        xanchor="center", x=0.5,
        bgcolor="rgba(255,255,255,0.9)",
        bordercolor="gray",
        borderwidth=1
    )
)

fig.update_yaxes(title_text="Proportion of Individuals", range=[0, 0.4], tickformat='.2f', gridcolor='lightgray')
fig.update_xaxes(title_text="<b>Difficulty Walking Status</b>", row=1, col=1)
fig.update_xaxes(title_text="<b>Cholesterol Check Status</b>", row=1, col=2)

fig.show()

"""- Khó khăn khi đi bộ (DiffWalk = 1) có liên quan mạnh với tỷ lệ mắc bệnh tiểu đường (30,8% so với 11,8%), phản ánh tình trạng suy giảm chức năng vận động thường gặp ở bệnh nhân tiểu đường đã có biến chứng hoặc các yếu tố nguy cơ nặng.
- Tỷ lệ tiểu đường ở nhóm đã kiểm tra cholesterol cao hơn rất nhiều (15,8% so với 2,6%) chủ yếu do nhóm này chứa phần lớn người lớn tuổi và có nguy cơ tim mạch cao, chứ không chứng tỏ việc kiểm tra cholesterol làm tăng nguy cơ tiểu đường. Đây là hiện tượng nhiễu do chỉ định khám bệnh (confounding by indication).

# 7. Xây dựng mô hình

## 7.1 Tiền xử lý dữ liệu
"""

df.info()

"""***Xác định các biến có giá trị ngoại lai: BMI, PhysHlth, MentHlth***"""

# ================================
# 1. Các cột cần xử lý outlier
# ================================
cols = ["BMI", "PhysHlth", "MentHlth"]
df_raw = df.copy()

# ================================
# Hàm detect outlier bằng IQR
# ================================
def detect_outliers_iqr(data, col):
    Q1 = data[col].quantile(0.25)
    Q3 = data[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return data[(data[col] < lower) | (data[col] > upper)].index

# ================================
# (A) Chỉ IQR → Xóa dòng
# ================================
df_iqr = df.copy()
outlier_idx_iqr = set()
for c in cols:
    outlier_idx_iqr.update(detect_outliers_iqr(df_iqr, c))

df_iqr = df_iqr.drop(index=outlier_idx_iqr)
removed_iqr = len(df_raw) - len(df_iqr)

# ================================
# (B) Chỉ Winsorization (thường dùng 5% mỗi bên hoặc 1%/99%)
# ================================
df_win = df.copy()

# Sửa lại: dùng limits đối xứng hợp lý hơn, ví dụ 5% mỗi bên
for c in cols:
    df_win[c] = winsorize(df_win[c], limits=[0.05, 0.05])  # 5% dưới + 5% trên

# Đếm số giá trị bị thay đổi
changed_win = sum((df_win[c] != df_raw[c]).sum() for c in cols)

# ================================
# (C) Winsorization + IQR (phương pháp an toàn nhất)
# ================================
df_wi = df.copy()

# Bước 1: Winsorize trước (giảm tác động của extreme values)
for c in cols:
    df_wi[c] = winsorize(df_wi[c], limits=[0.05, 0.05])

# Bước 2: Sau đó mới dùng IQR để xóa các outlier còn lại
outlier_idx_wi = set()
for c in cols:
    outlier_idx_wi.update(detect_outliers_iqr(df_wi, c))

df_wi = df_wi.drop(index=outlier_idx_wi)
removed_wi = len(df_raw) - len(df_wi)

# ================================
# 3. In kết quả chính xác
# ================================
print("===== SỐ LƯỢNG DÒNG/GIÁ TRỊ BỊ ẢNH HƯỞNG =====")
print(f"1. IQR (xóa dòng)              → Xóa: {removed_iqr:,} dòng ({removed_iqr/len(df_raw)*100:.2f}%)")
print(f"2. Winsorization 5% mỗi bên    → Thay đổi: {changed_win:,} giá trị")
print(f"3. Winsorization + IQR             → Xóa: {removed_wi:,} dòng ({removed_wi/len(df_raw)*100:.2f}%)")

print("\n===== KÍCH THƯỚC DATAFRAME =====")
print(f"Original          : {df_raw.shape}")
print(f"Chỉ IQR           : {df_iqr.shape}")
print(f"Chỉ Winsorization : {df_win.shape}")
print(f"Winsorization + IQR      : {df_wi.shape}")

"""-> Chọn Winsorization và Winsorization + IQR"""

df1 =df_win.copy().drop(columns=['BMI_bin'])
df2 = df_wi.copy().drop(columns=['BMI_bin'])

df1.info()
df2.info()

"""## 7.2 Chọn các biến quan trọng"""

def perform_feature_selection(df, target_col='Diabetes_binary'):
    """
    Thực hiện chọn lọc thuộc tính bằng Chi-squared và ANOVA F-statistic.

    Args:
        df (pd.DataFrame): DataFrame đầu vào (df1 hoặc df2).
        target_col (str): Tên cột mục tiêu.

    Returns:
        pd.DataFrame: DataFrame chứa kết quả F-Score và P-Value đã được sắp xếp.
    """

    y = df[target_col]
    X = df.drop(columns=[target_col])

    # Phân loại cột
    numerical_cols = X.select_dtypes(include=np.number).columns.tolist()
    # Giả định các biến định tính ở đây là các biến đã được mã hóa thành số nguyên/float
    # trong quá trình tiền xử lý, nên hầu hết đã nằm trong numerical_cols.
    categorical_cols = X.select_dtypes(exclude=np.number).columns.tolist() # Kiểm tra các biến chưa phải là số

    all_scores = []

    # --- A. Xử lý Biến Định tính (Categorical) bằng Chi-squared Test ---
    if categorical_cols:
        X_cat = X[categorical_cols]
        # Chi-squared Test yêu cầu X phải là số nguyên không âm.
        # Nếu có cột định tính, chúng ta cần đảm bảo chúng đã được mã hóa (ví dụ: Label Encoding).

        # Áp dụng SelectKBest (chi2)
        selector_chi2 = SelectKBest(score_func=chi2, k='all')
        selector_chi2.fit(X_cat, y)

        chi2_scores = pd.DataFrame({
            'Feature': categorical_cols,
            'Score': selector_chi2.scores_,
            'P_Value': selector_chi2.pvalues_,
            'Method': 'Chi2'
        })
        all_scores.append(chi2_scores)

    # --- B. Xử lý Biến Số (Numerical) bằng ANOVA F-statistic ---
    if numerical_cols:
        X_num = X[numerical_cols]

        # Áp dụng SelectKBest (f_classif - tương đương ANOVA)
        selector_anova = SelectKBest(score_func=f_classif, k='all')
        selector_anova.fit(X_num, y)

        anova_scores = pd.DataFrame({
            'Feature': numerical_cols,
            'Score': selector_anova.scores_,
            'P_Value': selector_anova.pvalues_,
            'Method': 'ANOVA (F-stat)'
        })
        all_scores.append(anova_scores)

    # Kết hợp tất cả kết quả và sắp xếp theo Score (hoặc P_Value)
    if all_scores:
        final_scores = pd.concat(all_scores, ignore_index=True)
        # Sắp xếp theo P_Value tăng dần (hoặc Score giảm dần)
        final_scores = final_scores.sort_values(by='P_Value', ascending=True).reset_index(drop=True)
        return final_scores
    else:
        return pd.DataFrame()

# =========================================================================
# === ÁP DỤNG HÀM CHO DF1 VÀ DF2 ===
# =========================================================================
TARGET_COL = 'Diabetes_binary'

# Lưu ý: Cần đảm bảo df1 và df2 đã tồn tại và được tiền xử lý trước đó.

print("===== KẾT QUẢ CHỌN LỌC THUỘC TÍNH (DF1) =====")
anova_results_df1 = perform_feature_selection(df1, TARGET_COL)
print(anova_results_df1)

print("\n===== KẾT QUẢ CHỌN LỌC THUỘC TÍNH (DF2) =====")
anova_results_df2 = perform_feature_selection(df2, TARGET_COL)
print(anova_results_df2)

# --- BƯỚC KẾT TIẾP: CHỌN 15 THUỘC TÍNH HÀNG ĐẦU ---
top_15_features_list_df1 = anova_results_df1['Feature'].head(15).tolist()
top_15_features_list_df2 = anova_results_df2['Feature'].head(15).tolist()

print("\n--- Top 15 Features được chọn từ DF1 ---")
print(top_15_features_list_df1)

print("\n--- Top 15 Features được chọn từ DF2 ---")
print(top_15_features_list_df2)

# Giả định:
# 1. Các DataFrame df1 và df2 đã tồn tại.
# 2. TARGET_COL = 'Diabetes_binary'
# 3. Các danh sách top_15_features_list_df1 và top_15_features_list_df2 đã được tạo
#    từ đoạn code ở bước trước.

TARGET_COL = 'Diabetes_binary'

# =======================================================
# === THỰC HIỆN LỌC DỮ LIỆU CHO DF1 VÀ DF2 ===
# =======================================================

# --- 1. Lọc DataFrame df1 ---
# Tạo danh sách các cột cuối cùng cho df1 (15 features + target)
modeling_cols_df1 = top_15_features_list_df1 + [TARGET_COL]
df1 = df1[modeling_cols_df1].copy()

# --- 2. Lọc DataFrame df2 ---
# Tạo danh sách các cột cuối cùng cho df2 (15 features + target)
modeling_cols_df2 = top_15_features_list_df2 + [TARGET_COL]
df2 = df2[modeling_cols_df2].copy()

df1.info()
df2.info()

"""## 7.3 Chia tập train và test"""

# Giả định TARGET_COL = 'Diabetes_binary'
TARGET_COL = 'Diabetes_binary'
RANDOM_SEED = 42 # Đặt seed để đảm bảo kết quả có thể tái lập

# ===============================================
# === 1. CHIA TẬP DỮ LIỆU DF1 (Dùng cho mô hình cây) ===
# ===============================================
X1 = df1.drop(columns=[TARGET_COL])
y1 = df1[TARGET_COL]

X1_train, X1_test, y1_train, y1_test = train_test_split(
    X1,
    y1,
    test_size=0.2,       # 20% cho tập kiểm tra
    random_state=RANDOM_SEED,
    stratify=y1          # Đảm bảo tỉ lệ y trong train/test giống nhau
)

print("===== KÍCH THƯỚC DF1 (Winsorization) =====")
print(f"Tổng số dòng: {len(df1):,}")
print(f"X1_train: {X1_train.shape}")
print(f"X1_test: {X1_test.shape}")
print(f"Tỉ lệ target y1_train: {y1_train.mean():.4f}")
print(f"Tỉ lệ target y1_test: {y1_test.mean():.4f}")

# ===============================================
# === 2. CHIA TẬP DỮ LIỆU DF2 (Dùng cho mô hình tuyến tính/khoảng cách) ===
# ===============================================
X2 = df2.drop(columns=[TARGET_COL])
y2 = df2[TARGET_COL]

X2_train, X2_test, y2_train, y2_test = train_test_split(
    X2,
    y2,
    test_size=0.2,       # 20% cho tập kiểm tra
    random_state=RANDOM_SEED,
    stratify=y2          # Đảm bảo tỉ lệ y trong train/test giống nhau
)

print("\n===== KÍCH THƯỚC DF2 (Winsorize + IQR) =====")
print(f"Tổng số dòng: {len(df2):,}")
print(f"X2_train: {X2_train.shape}")
print(f"X2_test: {X2_test.shape}")
print(f"Tỉ lệ target y2_train: {y2_train.mean():.4f}")
print(f"Tỉ lệ target y2_test: {y2_test.mean():.4f}")

"""## 7.4 Train

#### 7.4.1 DF1: Winsorize
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report
import time

# Giả định X1_train, y1_train, X1_test, y1_test đã được chia ở bước trước
# Giả định TARGET_COL = 'Diabetes_binary'

# Khởi tạo DataFrame để lưu trữ kết quả đánh giá
results_df1 = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC', 'Training_Time (s)'])
RANDOM_SEED = 42

# Hàm đánh giá mô hình
def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):
    """Huấn luyện và đánh giá mô hình phân loại."""

    start_time = time.time()
    # Huấn luyện
    model.fit(X_train, y_train)
    training_time = time.time() - start_time

    # Dự đoán trên tập kiểm tra
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1] # Xác suất cho lớp dương tính (lớp 1)

    # Tính toán Metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, zero_division=0)
    recall = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    roc_auc = roc_auc_score(y_test, y_proba)

    # In báo cáo chi tiết
    print(f"\n--- BÁO CÁO PHÂN LOẠI: {model_name} ---")
    print(classification_report(y_test, y_pred, digits=4))

    return [model_name, accuracy, precision, recall, f1, roc_auc, training_time]

# =========================================================================
# === HUẤN LUYỆN VÀ ĐÁNH GIÁ CÁC MÔ HÌNH ===
# =========================================================================

# 1. Decision Tree (DT)
# DT cơ bản không có tham số cân bằng lớp tích hợp, kết quả sẽ thiên về lớp đa số.
print("\n[BẮT ĐẦU HUẤN LUYỆN: Decision Tree]")
dt_model = DecisionTreeClassifier(random_state=RANDOM_SEED)
dt_scores = evaluate_model(dt_model, X1_train, y1_train, X1_test, y1_test, "Decision Tree")
results_df1.loc[len(results_df1)] = dt_scores

# 2. Random Forest (RF)
# SỬ DỤNG: class_weight='balanced' để cân bằng lớp
print("\n[BẮT ĐẦU HUẤN LUYỆN: Random Forest]")
rf_model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED, class_weight='balanced')
rf_scores = evaluate_model(rf_model, X1_train, y1_train, X1_test, y1_test, "Random Forest")
results_df1.loc[len(results_df1)] = rf_scores

# 3. XGBoost
# SỬ DỤNG: scale_pos_weight để cân bằng lớp
# Tính toán tỷ lệ: (Tổng số âm / Tổng số dương)
scale_pos_weight_val = len(y1_train[y1_train == 0]) / len(y1_train[y1_train == 1])

print("\n[BẮT ĐẦU HUẤN LUYỆN: XGBoost]")
xgb_model = XGBClassifier(
    objective='binary:logistic',
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=RANDOM_SEED,
    scale_pos_weight=scale_pos_weight_val
)
xgb_scores = evaluate_model(xgb_model, X1_train, y1_train, X1_test, y1_test, "XGBoost")
results_df1.loc[len(results_df1)] = xgb_scores

print("\n========================================================")
print("=== TÓM TẮT KẾT QUẢ ĐÁNH GIÁ MÔ HÌNH TRÊN DF1 (X1-TEST) ===")
print("========================================================")
# Làm tròn kết quả
results_df1[['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']] = results_df1[['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']].apply(lambda x: x.round(4))
print(results_df1.set_index('Model'))

"""#### 7.4.2 DF2: Winsorize + IQR"""

from sklearn.preprocessing import StandardScaler


# 1. Khởi tạo Scaler
scaler = StandardScaler()

# 2. Học (fit) trên tập huấn luyện X2_train
X2_train_scaled = scaler.fit_transform(X2_train)

# 3. Áp dụng (transform) lên cả X2_train và X2_test
X2_test_scaled = scaler.transform(X2_test)

# Chuyển đổi lại thành DataFrame để dễ theo dõi (tùy chọn)
X2_train_scaled = pd.DataFrame(X2_train_scaled, columns=X2_train.columns)
X2_test_scaled = pd.DataFrame(X2_test_scaled, columns=X2_test.columns)

print("✅ Đã hoàn thành Chuẩn hóa dữ liệu cho X2_train và X2_test.")
print(f"Giá trị trung bình của cột đầu tiên trong X2_train_scaled (gần 0): {X2_train_scaled.iloc[:, 0].mean():.2f}")
print("---")

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report
import time
import pandas as pd

# Khởi tạo DataFrame để lưu trữ kết quả đánh giá cho df2
results_df2 = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC', 'Training_Time (s)'])

RANDOM_SEED = 42
# Tính toán scale_pos_weight cho XGBoost, nhưng chúng ta sẽ dùng class_weight='balanced' ở đây
# Tỷ lệ: (Tổng số âm / Tổng số dương)
class_weights_df2 = {0: 1, 1: len(y2_train[y2_train == 0]) / len(y2_train[y2_train == 1])}

# Hàm đánh giá mô hình (sử dụng hàm đã định nghĩa trước đó)
# ... (Hàm evaluate_model đã được định nghĩa ở bước trước) ...
# Lưu ý: Hàm này cần được định nghĩa lại hoặc đảm bảo đã được định nghĩa trong phiên làm việc.

# 1. Logistic Regression
print("\n[BẮT ĐẦU HUẤN LUYỆN: Logistic Regression]")
logreg_model = LogisticRegression(random_state=RANDOM_SEED, solver='liblinear', class_weight='balanced')
logreg_scores = evaluate_model(logreg_model, X2_train_scaled, y2_train, X2_test_scaled, y2_test, "Logistic Regression")
results_df2.loc[len(results_df2)] = logreg_scores

# 2. Support Vector Machine (SVM)
# SVM có thể chạy chậm trên dữ liệu lớn. Sử dụng kernel='linear' và class_weight='balanced'.
print("\n[BẮT ĐẦU HUẤN LUYỆN: Support Vector Machine]")
# Giới hạn số lượng mẫu nếu chạy quá lâu
if len(X2_train_scaled) > 50000:
    # Lấy mẫu ngẫu nhiên (chỉ là ví dụ, nếu cần thiết)
    X2_train_sample, _, y2_train_sample, _ = train_test_split(
        X2_train_scaled, y2_train, train_size=50000, stratify=y2_train, random_state=RANDOM_SEED
    )
    X_train_svm = X2_train_sample
    y_train_svm = y2_train_sample
else:
    X_train_svm = X2_train_scaled
    y_train_svm = y2_train

svm_model = SVC(kernel='linear', probability=True, random_state=RANDOM_SEED, class_weight='balanced')
svm_scores = evaluate_model(svm_model, X_train_svm, y_train_svm, X2_test_scaled, y2_test, "Support Vector Machine")
results_df2.loc[len(results_df2)] = svm_scores

# 3. Multi-Layer Perceptron (MLP)
print("\n[BẮT ĐẦU HUẤN LUYỆN: MLP (Neural Network)]")
mlp_model = MLPClassifier(random_state=RANDOM_SEED, max_iter=300, hidden_layer_sizes=(100, 50), early_stopping=True)
# MLP không có tham số class_weight tích hợp, nên cần xử lý mất cân bằng bằng cách khác (ví dụ: SMOTE, nhưng ta tạm dùng MLP cơ bản)
mlp_scores = evaluate_model(mlp_model, X2_train_scaled, y2_train, X2_test_scaled, y2_test, "MLP")
results_df2.loc[len(results_df2)] = mlp_scores

print("\n========================================================")
print("=== TÓM TẮT KẾT QUẢ ĐÁNH GIÁ MÔ HÌNH TRÊN DF2 (X2-TEST) ===")
print("========================================================")
# Làm tròn kết quả
results_df2[['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']] = results_df2[['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']].apply(lambda x: x.round(4))
print(results_df2.set_index('Model'))

"""# 8. Chọn mô hình và triển khai

Chọn XGBoost vì:

  - AUC cao nhất trong các mô hình ổn định
  - Recall rất tốt (0.76–0.78)
"""

import joblib

# Lưu mô hình XGBoost
model_filename = 'xgboost_diabetes_model.joblib'
joblib.dump(xgb_model, model_filename)

print(f"Mô hình XGBoost đã được lưu vào: {model_filename}")